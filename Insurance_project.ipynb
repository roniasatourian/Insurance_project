{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "8193F9fDWcHH"
      },
      "outputs": [],
      "source": [
        "# !pip install fancyimpute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "flKeWxkptRXy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import calendar\n",
        "from sklearn.impute import KNNImputer\n",
        "from fancyimpute import IterativeImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import lightgbm as lgb\n",
        "import pickle\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Vd1lz2okG3f7"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/exercise_40_train.csv')\n",
        "df_test = pd.read_csv('/content/exercise_40_test.csv')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "2EH1CQz8m__5"
      },
      "source": [
        "#EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "V05yzOKcv_Kp",
        "outputId": "a9d6d35c-0c66-46fb-f4a0-db15f609ed2e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Check the training data too see if its balanced or not\n",
        "# Count the number of occurrences of each value in the y column\n",
        "target_counts = df_train['y'].value_counts()\n",
        "\n",
        "# Create the bar plot\n",
        "target_counts.plot(kind='bar');\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Categories')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Balance of y')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2z4Bc-ynBSN",
        "outputId": "3335a0cf-82fc-479a-89ec-6e76ccdaa477"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'x3': array(['Wed', 'Friday', 'Thursday', 'Tuesday', 'Sunday', 'Saturday',\n",
            "       'Sat', 'Wednesday', 'Sun', 'Tue', 'Thur', 'Monday', 'Fri', 'Mon'],\n",
            "      dtype=object), 'x7': array(['0.0062%', '0.0064%', '-8e-04%', '-0.0057%', '0.0109%', '0.0079%',\n",
            "       '0.0174%', '-0.0106%', '0.0032%', '0.0091%', '-0.0052%',\n",
            "       '-0.0025%', '-0.0045%', '0.0068%', '-0.0137%', '-0.0014%',\n",
            "       '-0.0013%', '0.0066%', '0.0097%', '-0.0086%', '0.0023%',\n",
            "       '-0.0023%', '-0.0107%', '-0.0134%', '0.0058%', '-2e-04%',\n",
            "       '-0.0033%', '-0.0172%', '-0.0026%', '-0.0118%', '0.0105%',\n",
            "       '-0.0055%', '0.0095%', '0.0026%', '-0.0051%', '0.0054%',\n",
            "       '-0.0167%', '0.0015%', '-0.0037%', '0.0011%', '-0.0097%',\n",
            "       '-0.0016%', '-0.0155%', '0.015%', '-0.0032%', '2e-04%', '0.0122%',\n",
            "       '0.0082%', '-0.0054%', '-0.0017%', '0.0013%', '0.0025%',\n",
            "       '-0.0021%', '-0.017%', '-0.005%', '0.0014%', '-0.0103%', '-0.018%',\n",
            "       '-0.0077%', '-0.0115%', '-0.0018%', '6e-04%', '-0.0169%',\n",
            "       '0.0051%', '0.0093%', '-0.0043%', '0.0157%', '-0.0012%', '0.0056%',\n",
            "       '-0.0035%', '0.005%', '0.0073%', '0.0127%', '0.0098%', '-0.0022%',\n",
            "       '-0.0146%', '-0.0168%', '0.001%', '-0.016%', '0.0049%', '0.0034%',\n",
            "       '0.0043%', '0.0017%', '-0.0179%', '0.007%', '-0.003%', '-0.0059%',\n",
            "       '-0.004%', '0.017%', '0.0045%', '0.0052%', '-0.006%', '-0.0159%',\n",
            "       '-0.011%', '0.004%', '0.0149%', '0.0148%', '0.0203%', '-0.0019%',\n",
            "       '0.0061%', '-3e-04%', '-0.0176%', '-0.0102%', '0.0094%',\n",
            "       '-0.0131%', '-0.0027%', '5e-04%', '0.0048%', '-0.0058%',\n",
            "       '-0.0068%', '0.0229%', '0.0087%', '0.0212%', '0.0024%', '0.0019%',\n",
            "       '-0.0063%', '0.0112%', '0.0089%', '0.002%', '0.0262%', '-0.0064%',\n",
            "       '-1e-04%', '0.0154%', '-0.009%', '3e-04%', '0.0193%', '-0.0114%',\n",
            "       '-0.0105%', '-0.0165%', '0.0021%', '0.0039%', '0.0088%', '0.0156%',\n",
            "       '0.0133%', '-0.0073%', '-0.001%', '0.0162%', '0.0136%', '0.0092%',\n",
            "       '-0.0111%', '0.0219%', '0.006%', '0.0171%', '-0.0062%', '0.0146%',\n",
            "       '0.0044%', '-0.012%', '-0.0042%', '0.0113%', '0.009%', '0.0029%',\n",
            "       '-0.0074%', '-0.0121%', '0.0099%', '-0.0083%', '-0.0109%',\n",
            "       '-0.0138%', '-0.0071%', '0.0038%', '-0.022%', '0.018%', '0.0074%',\n",
            "       '1e-04%', '0.0114%', '9e-04%', '0.0028%', '-0.0135%', '-0.0089%',\n",
            "       '0.0167%', '0.0047%', '0.0164%', '0.0216%', '-0.0092%', '0.0081%',\n",
            "       '0.0103%', '-0.0181%', '-0.0195%', '-0.0213%', '0.0072%',\n",
            "       '0.0031%', '0.0111%', '-0.0041%', '-0.007%', '0.0059%', '0.0077%',\n",
            "       '0.0071%', '-0.0153%', '-0.0185%', '0.0053%', '-0.0117%',\n",
            "       '0.0027%', '0.01%', '0.0168%', '-0.0184%', '0.0022%', '0.0192%',\n",
            "       '0.0125%', '-0.0156%', '0.0159%', '-0.014%', '0.0085%', '-0.021%',\n",
            "       '-0.0183%', '-0.0036%', '-0.0149%', '-0.0053%', '0.0132%',\n",
            "       '-0.0145%', '0.0057%', '0.0151%', '0.023%', '0.0158%', '0.0108%',\n",
            "       '-0.0075%', '-0.0125%', '-0.0048%', '-0.0087%', '-0.0015%',\n",
            "       '0.0172%', '0.0115%', '-0.0024%', '-9e-04%', '-0.0108%', '0.0037%',\n",
            "       '0.0102%', '-0.0056%', '-0.002%', '-0.0067%', '0.0207%',\n",
            "       '-0.0157%', '4e-04%', '-0.0112%', '0.0041%', '0.0145%', '-0.0124%',\n",
            "       '-6e-04%', '0.003%', '0.0069%', '0.0065%', '-0.0273%', '-0.0116%',\n",
            "       '0.0124%', '-0.0275%', '-0.0226%', '0.0078%', '-0.0038%',\n",
            "       '0.0138%', '-0.025%', '0.0144%', '-0.0126%', '0.0063%', '0.0067%',\n",
            "       '0.0101%', '0.0033%', '0.0096%', '-0.0093%', '-0.0031%', '7e-04%',\n",
            "       '0.0042%', '-0.0082%', '-0.0029%', '0.0012%', '-0.0204%',\n",
            "       '-0.0046%', '0.0046%', '0.0185%', '-0.0207%', '-0.0151%',\n",
            "       '-0.0127%', '0.0116%', '-0.0163%', '-0.0094%', '-0.0061%',\n",
            "       '-0.0136%', '-0.0044%', '-0.0133%', '-0.0078%', '0%', '0.0215%',\n",
            "       '0.0121%', '-0.0079%', '-0.0095%', '-0.013%', '-7e-04%',\n",
            "       '-0.0143%', '-0.02%', '0.008%', '-0.0202%', '-0.0148%', '0.0161%',\n",
            "       '0.016%', '-0.0081%', '0.0118%', '0.0175%', '-0.0076%', '0.0265%',\n",
            "       '-0.0178%', '0.0226%', '0.0153%', '-0.0122%', '0.0165%', '0.0104%',\n",
            "       '0.0209%', '-0.0099%', '0.0222%', '0.0224%', '0.012%', '0.0036%',\n",
            "       '-0.0113%', '-0.0182%', '-0.0123%', '0.0083%', '0.0152%',\n",
            "       '0.0183%', '-0.0066%', '-0.0161%', '0.0139%', '-0.0098%',\n",
            "       '-0.0241%', '0.0288%', '0.0076%', '0.0086%', '0.011%', '-0.0132%',\n",
            "       '-0.01%', '-0.0144%', '-0.0047%', '-0.0119%', '-0.0034%',\n",
            "       '0.0018%', '-0.0011%', '0.014%', '-0.008%', '-0.0085%', '0.0084%',\n",
            "       '0.0107%', '0.0208%', '0.0142%', '0.0135%', '0.022%', '0.0016%',\n",
            "       '-0.0173%', '0.0055%', '0.0117%', '0.021%', '0.0137%', '-0.0141%',\n",
            "       '-0.0039%', '-0.0177%', '0.0232%', '-0.0292%', '0.0247%',\n",
            "       '0.0176%', '-0.0186%', '0.0035%', '0.0295%', '0.0188%', '0.0199%',\n",
            "       '-0.0262%', '-0.0259%', '-0.0272%', '0.0213%', '-0.0049%',\n",
            "       '-0.0193%', '-0.0028%', '0.0272%', '-0.0069%', '-0.0198%',\n",
            "       '-0.0166%', '0.0264%', '-5e-04%', '0.0301%', '-0.0171%', '0.0106%',\n",
            "       '0.0254%', '0.0195%', '0.0143%', '-0.0152%', '0.0198%', '0.0123%',\n",
            "       '0.0181%', '-0.0129%', '-0.0206%', '0.0266%', '-0.0084%',\n",
            "       '-0.0101%', '-0.0222%', '-0.0154%', '-0.0065%', '0.0267%',\n",
            "       '0.0255%', '0.0119%', '8e-04%', '-4e-04%', '-0.0277%', '0.0169%',\n",
            "       '-0.0091%', '0.0177%', '0.0184%', '-0.0276%', '-0.0235%',\n",
            "       '0.0134%', '0.0128%', '-0.0203%', '-0.0175%', '0.0189%', '0.0242%',\n",
            "       '0.0129%', '-0.0147%', '0.0131%', '0.0141%', '-0.015%', '0.0201%',\n",
            "       '-0.0142%', '0.0179%', '-0.026%', '0.0182%', '0.0335%', '-0.0197%',\n",
            "       '0.0206%', '-0.0139%', '-0.0254%', '0.0187%', '0.029%', '-0.0072%',\n",
            "       '-0.0208%', '0.0166%', '-0.0162%', '0.0231%', '0.0163%',\n",
            "       '-0.0194%', '-0.0221%', '0.0233%', '-0.0244%', '-0.0104%',\n",
            "       '0.0126%', '-0.0164%', '0.032%', '-0.0199%', '-0.0322%', '0.0173%',\n",
            "       '0.0075%', '-0.0265%', '-0.0128%', '-0.0158%', '-0.0249%',\n",
            "       '-0.0201%', '0.0256%', '-0.0188%', '-0.023%', '-0.0238%',\n",
            "       '-0.0214%', '-0.0278%', '0.0191%', '0.02%', '0.0194%', '-0.0228%',\n",
            "       '-0.0245%', '-0.0242%', '-0.0223%', '-0.019%', '0.0269%',\n",
            "       '0.0314%', '-0.0217%', '0.0235%', '0.0196%', '0.0323%', '0.0147%',\n",
            "       '0.0234%', '0.024%', '-0.0196%', '0.0204%', '-0.0192%', '0.026%',\n",
            "       '0.0305%', '-0.0174%', '0.0211%', '-0.0209%', '-0.0224%',\n",
            "       '-0.0281%', '-0.0247%', '-0.0096%', '0.0202%', '0.0227%',\n",
            "       '-0.0236%', '-0.0218%', '-0.0252%', '0.019%', '0.0155%', '0.0221%',\n",
            "       '-0.0215%', '0.0284%', '0.0251%', '-0.0191%', '-0.0219%',\n",
            "       '0.0178%', '0.0241%', '0.0186%', '0.0228%', '-0.0187%', '-0.0233%',\n",
            "       '0.0214%', '-0.0261%', '0.0271%', '-0.0271%', '-0.0269%',\n",
            "       '0.0274%', '0.0252%', '0.0225%', '-0.0257%', '-0.0308%', '0.0331%',\n",
            "       '-0.0234%', '0.0263%', '-0.0088%', '-0.0189%', '-0.0392%',\n",
            "       '-0.0297%', '-0.0211%', '0.0281%', '0.0243%', '0.0258%',\n",
            "       '-0.0264%', '-0.0246%', '0.0197%', '-0.0237%', '-0.0336%',\n",
            "       '0.0237%', '0.0217%', '0.013%', '-0.0314%', '-0.0216%', '0.0238%',\n",
            "       '0.0286%', '-0.0289%', '-0.0263%', '-0.0258%', '-0.0286%',\n",
            "       '-0.031%', '0.0268%', '0.0218%', '-0.0266%', '-0.0319%', '0.027%',\n",
            "       '-0.0205%', '-0.0282%', '-0.0225%', '0.028%', '-0.0255%', '0.025%',\n",
            "       '-0.0239%', '0.0297%', '0.0245%', '0.0244%', '-0.024%', '0.0249%',\n",
            "       '0.0223%', '0.0257%', '0.0296%', '-0.0227%', '0.0303%', '0.0248%',\n",
            "       '-0.0298%', '-0.0248%', '0.0334%', '-0.0327%', '-0.0232%',\n",
            "       '0.0277%', '0.0253%', '0.0246%', '0.0294%', '0.0328%', '-0.0212%',\n",
            "       '0.0239%', '0.0287%', '0.0311%', '0.0321%', '-0.028%', '0.0261%',\n",
            "       '-0.0283%', '0.0346%', '-0.0285%', '0.0359%', '0.0317%', '0.0278%',\n",
            "       '0.0312%', '0.0302%', '-0.0315%', '-0.0229%', '0.0205%', '0.0304%',\n",
            "       '-0.0279%', '0.0356%', '-0.0299%', '0.0298%', '-0.0345%',\n",
            "       '-0.0303%', '0.0339%', '0.0273%', '0.0236%', '0.0315%', '-0.0316%',\n",
            "       '-0.0307%', '-0.0323%', '-0.0253%', '-0.0294%', '-0.0231%',\n",
            "       '-0.0251%', '0.0292%', '-0.0332%', '0.0279%', '-0.0291%',\n",
            "       '0.0306%', '-0.0335%', '0.0283%', '0.0319%', '-0.0378%',\n",
            "       '-0.0267%', '0.0379%', '0.031%', '-0.0438%', '0.0349%', '0.0293%',\n",
            "       '-0.0288%', '-0.0301%', '-0.0268%', '-0.0302%', '0.0299%',\n",
            "       '0.0259%', '0.0337%', '0.0316%', '0.0276%', '-0.0408%', '0.0291%',\n",
            "       '-0.027%', '-0.0312%', '-0.0412%', '-0.0313%', '-0.029%',\n",
            "       '-0.0339%', '-0.0406%', '0.0318%', '-0.0328%', '0.0342%',\n",
            "       '0.0282%', '-0.0405%', '-0.0287%', '-0.0274%', '-0.0296%', '0.03%',\n",
            "       '0.0324%', '0.0344%', '-0.0324%', '0.0289%', '0.0325%', '-0.0243%',\n",
            "       '-0.0338%', '-0.0318%', '-0.0311%', '-0.0256%', '-0.0373%',\n",
            "       '0.0354%', '-0.0293%'], dtype=object), 'x19': array(['$-908.650758424405', '$-1864.9622875143', '$-543.187402955527',\n",
            "       ..., '$834.95775080472', '$-48.1031003332715', '$96.0017151741518'],\n",
            "      dtype=object), 'x24': array(['female', 'male', nan], dtype=object), 'x31': array(['no', 'yes'], dtype=object), 'x33': array(['Colorado', 'Tennessee', 'Texas', 'Minnesota', 'New York',\n",
            "       'Florida', 'Nebraska', 'California', nan, 'North Dakota',\n",
            "       'Arizona', 'Alabama', 'Ohio', 'Pennsylvania', 'Iowa', 'Indiana',\n",
            "       'Vermont', 'Arkansas', 'Massachusetts', 'Illinois', 'Georgia',\n",
            "       'West Virginia', 'Connecticut', 'Virginia', 'North Carolina',\n",
            "       'Montana', 'New Mexico', 'New Hampshire', 'Michigan', 'DC',\n",
            "       'Washington', 'Louisiana', 'Kentucky', 'Utah', 'Missouri',\n",
            "       'Oregon', 'Oklahoma', 'Nevada', 'Wisconsin', 'New Jersey',\n",
            "       'Maryland', 'Maine', 'Alaska', 'Idaho', 'Wyoming', 'Rhode Island',\n",
            "       'South Dakota', 'Mississippi', 'Kansas', 'Delaware', 'Hawaii',\n",
            "       'South Carolina'], dtype=object), 'x39': array(['5-10 miles'], dtype=object), 'x60': array(['August', 'April', 'September', 'January', 'December', 'March',\n",
            "       'July', 'November', 'June', 'February', 'October', 'May'],\n",
            "      dtype=object), 'x65': array(['farmers', 'allstate', 'geico', 'progressive', 'esurance'],\n",
            "      dtype=object), 'x77': array(['mercedes', 'subaru', 'nissan', 'toyota', nan, 'chevrolet',\n",
            "       'buick', 'ford'], dtype=object), 'x93': array(['no', 'yes'], dtype=object), 'x99': array(['yes', nan], dtype=object)}\n"
          ]
        }
      ],
      "source": [
        "# Select all columns in the training dataframe that have an object data type (i.e. categorical columns)\n",
        "categorical_df = df_train.loc[:,df_train.dtypes == object]\n",
        "\n",
        "# Iterate over each categorical column and store its unique values in the dictionary\n",
        "cat_dict = {}\n",
        "for col in categorical_df.columns:\n",
        "  cat_dict[col] = categorical_df[col].unique()\n",
        "\n",
        "print(cat_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCcZ4nSMFCWy",
        "outputId": "f7d74a36-280d-4882-f671-d1d198d2a661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y 0\n",
            "x1 0\n",
            "x2 0\n",
            "x3 0\n",
            "x4 0\n",
            "x5 2428\n",
            "x6 0\n",
            "x7 0\n",
            "x8 0\n",
            "x9 0\n",
            "x10 0\n",
            "x11 5110\n",
            "x12 0\n",
            "x13 0\n",
            "x14 9864\n",
            "x15 0\n",
            "x16 11212\n",
            "x17 0\n",
            "x18 0\n",
            "x19 0\n",
            "x20 0\n",
            "x21 0\n",
            "x22 2387\n",
            "x23 0\n",
            "x24 3856\n",
            "x25 0\n",
            "x26 2433\n",
            "x27 0\n",
            "x28 0\n",
            "x29 0\n",
            "x30 32336\n",
            "x31 0\n",
            "x32 0\n",
            "x33 7171\n",
            "x34 0\n",
            "x35 0\n",
            "x36 0\n",
            "x37 0\n",
            "x38 2402\n",
            "x39 0\n",
            "x40 0\n",
            "x41 9503\n",
            "x42 9729\n",
            "x43 0\n",
            "x44 34247\n",
            "x45 8009\n",
            "x46 0\n",
            "x47 0\n",
            "x48 0\n",
            "x49 12823\n",
            "x50 0\n",
            "x51 0\n",
            "x52 16182\n",
            "x53 0\n",
            "x54 12728\n",
            "x55 17696\n",
            "x56 0\n",
            "x57 32464\n",
            "x58 0\n",
            "x59 0\n",
            "x60 0\n",
            "x61 7293\n",
            "x62 0\n",
            "x63 2420\n",
            "x64 5101\n",
            "x65 0\n",
            "x66 0\n",
            "x67 2425\n",
            "x68 2384\n",
            "x69 0\n",
            "x70 0\n",
            "x71 0\n",
            "x72 0\n",
            "x73 0\n",
            "x74 12916\n",
            "x75 5245\n",
            "x76 5249\n",
            "x77 9257\n",
            "x78 11373\n",
            "x79 2430\n",
            "x80 5256\n",
            "x81 0\n",
            "x82 0\n",
            "x83 2428\n",
            "x84 0\n",
            "x85 9715\n",
            "x86 2407\n",
            "x87 0\n",
            "x88 2331\n",
            "x89 10691\n",
            "x90 0\n",
            "x91 5259\n",
            "x92 2435\n",
            "x93 0\n",
            "x94 2340\n",
            "x95 12604\n",
            "x96 6638\n",
            "x97 0\n",
            "x98 0\n",
            "x99 12836\n",
            "x100 0\n"
          ]
        }
      ],
      "source": [
        "# Count the number of null values in train df\n",
        "for col in df_train.columns: \n",
        "  null_count = df_train[col].isnull().sum()\n",
        "  print(col,null_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "jon-3m-7LUav"
      },
      "outputs": [],
      "source": [
        "X_train = df_train.loc[:, df_train.columns != 'y']\n",
        "y_train = df_train['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ozIFnbTXMKhq"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_train,\n",
        "                                  y_train,\n",
        "                                  test_size=0.2,\n",
        "                                  random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vARrbFCAmw0Z"
      },
      "source": [
        "#Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "R91aKB3znqHs"
      },
      "outputs": [],
      "source": [
        "class Maid_Service:\n",
        "\n",
        "  def __init__(self):\n",
        "    # Initialize day_map dictionary to map abbreviated days of the week to their full names\n",
        "    self.day_map = {d.lower(): calendar.day_name[i].lower() for i, d in enumerate(calendar.day_abbr)}\n",
        "    # Modify day_map to handle 'thur' abbreviation\n",
        "    self.day_map['thur'] = self.day_map.pop('thu')\n",
        "\n",
        "  def set_dataframe(self,df,train = True):\n",
        "    # Set the dataframe and whether it is for training or testing\n",
        "    self.df = df\n",
        "    self.train = train\n",
        "\n",
        "  def numerise_percent_dollar_col(self):\n",
        "    # Convert columns with percentages and dollar signs to numerical values\n",
        "    self.df['x7'] = self.df['x7'].str.replace('%','').astype(float)\n",
        "    self.df['x19'] = self.df['x19'].str.replace('$','').astype(float) \n",
        "\n",
        "  def weekday_mod(self):\n",
        "    # Map abbreviated days of the week to their full names\n",
        "    self.df['x3'] = self.df['x3'].str.lower().replace(self.day_map)\n",
        "\n",
        "  def cat_num_sep(self):\n",
        "    # Split dataframe into categorical and numerical dataframes\n",
        "    self.category_df = self.df.loc[:,self.df.dtypes == object]\n",
        "    self.numerical_df = self.df.loc[:,(self.df.dtypes == np.float64) | (self.df.dtypes == np.int64)]\n",
        "\n",
        "  def knn_impute_cat(self):\n",
        "    # Impute missing values in categorical columns using KNN imputation\n",
        "    if self.train:\n",
        "      # Fit the encoder and KNN imputer on the training data\n",
        "      self.enc = OrdinalEncoder()\n",
        "      self.category_df[self.category_df.columns] = self.enc.fit_transform(self.category_df)\n",
        "\n",
        "      self.knn_imputer = KNNImputer(n_neighbors=3, weights='distance', metric='nan_euclidean', missing_values=float('nan'), add_indicator=False)\n",
        "      self.imputed_categorical_data = pd.DataFrame(self.knn_imputer.fit_transform(self.category_df), columns=self.category_df.columns)\n",
        "\n",
        "    else:\n",
        "      # Use the fitted encoder and KNN imputer on the testing data\n",
        "      self.category_df[self.category_df.columns] = self.enc.transform(self.category_df)\n",
        "      self.imputed_categorical_data = pd.DataFrame(self.knn_imputer.transform(self.category_df), columns=self.category_df.columns)\n",
        "\n",
        "  def mice_impute_num(self):\n",
        "    # Impute missing values in numerical columns using MICE imputation\n",
        "    if self.train:\n",
        "      # Fit the MICE imputer on the training data\n",
        "      self.mice_imputer = IterativeImputer()\n",
        "      self.imputed_numerical_data = pd.DataFrame(self.mice_imputer.fit_transform(self.numerical_df), columns=self.numerical_df.columns)\n",
        "    \n",
        "    else:\n",
        "      # Use the fitted MICE imputer on the testing data\n",
        "      self.imputed_numerical_data = pd.DataFrame(self.mice_imputer.transform(self.numerical_df), columns=self.numerical_df.columns)\n",
        "\n",
        "  def clean_pipeline(self,use_PCA = False):\n",
        "    # Run a pipeline of data cleaning and imputation methods\n",
        "    self.numerise_percent_dollar_col()    \n",
        "    self.weekday_mod()\n",
        "    self.cat_num_sep()\n",
        "    self.knn_impute_cat()\n",
        "    self.mice_impute_num()\n",
        "    \n",
        "    self.cleaned_df = pd.concat([self.imputed_categorical_data,self.imputed_numerical_data],axis = 1)\n",
        "\n",
        "    if use_PCA == True: # check if PCA should be applied\n",
        "      X = self.cleaned_df.loc[:, self.cleaned_df.columns != 'y'] \n",
        "      y = self.cleaned_df['y'] \n",
        "      if self.train: \n",
        "        # if in training mode\n",
        "        self.pca = PCA(n_components=30) # instantiate PCA object with 30 components\n",
        "        X_PCA = self.pca.fit_transform(X) # fit and transform the feature data to PCA\n",
        "      else: \n",
        "        # if in testing mode\n",
        "        X_PCA = self.pca.transform(X) # transform the feature data using pre-trained PCA\n",
        "\n",
        "      X_PCA_df = pd.DataFrame(X_PCA, columns=['PCA{}'.format(i+1) for i in range(X_PCA.shape[1])]) # create DataFrame from PCA-transformed feature data\n",
        "      y_df = pd.DataFrame(y, columns=['y']) # create DataFrame from target variable\n",
        "\n",
        "      self.pca_df = pd.concat([X_PCA_df,y_df],axis = 1)  \n",
        "      return self.pca_df # return the new DataFrame with PCA-transformed features and target variable\n",
        "      \n",
        "    return self.cleaned_df # if not using PCA, return the original cleaned data without modification\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kos5wejsuI5s",
        "outputId": "bbf2a831-d058-4f2c-edc6-30065a22a487"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-13-ea65178de5df>:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  self.df['x19'] = self.df['x19'].str.replace('$','').astype(float)\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = igetitem(value, i)\n",
            "<ipython-input-13-ea65178de5df>:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  self.df['x19'] = self.df['x19'].str.replace('$','').astype(float)\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = igetitem(value, i)\n",
            "<ipython-input-13-ea65178de5df>:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
            "  self.df['x19'] = self.df['x19'].str.replace('$','').astype(float)\n",
            "/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py:3678: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[col] = igetitem(value, i)\n"
          ]
        }
      ],
      "source": [
        "# Create ms object and run the tasks for train-val and test data\n",
        "ms = Maid_Service()\n",
        "ms.set_dataframe(X_train,train = True)\n",
        "cleaned_X_train_df = ms.clean_pipeline()\n",
        "\n",
        "ms.set_dataframe(X_val,train = False)\n",
        "cleaned_X_val_df = ms.clean_pipeline()\n",
        "\n",
        "ms.set_dataframe(df_test,train = False)\n",
        "cleaned_X_test_df = ms.clean_pipeline()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhV_-m3tzWkI"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bJ48gFIpnWD",
        "outputId": "ae8b0698-4296-4d52-a3a3-83e9e7637cfb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "RFECV(cv=5, estimator=LogisticRegression(), n_jobs=-1, scoring='roc_auc',\n",
              "      step=5)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Logistic Regression with recursive feature reduction, cv\n",
        "lr_clf = RFECV(LogisticRegression(),\n",
        "      scoring = 'roc_auc',\n",
        "      n_jobs = -1,\n",
        "      cv = 5,\n",
        "      step = 5)\n",
        "\n",
        "lr_clf.fit(cleaned_X_train_df, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHiCkuI7pn3V",
        "outputId": "01846666-b497-4746-d4db-0ad93081f837"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC:  0.6662395359050629\n",
            "Accuracy:  0.8575\n"
          ]
        }
      ],
      "source": [
        "# Prediction Probs\n",
        "lr_clf_probs = lr_clf.predict_proba(cleaned_X_val_df)\n",
        "print('AUC: ', roc_auc_score(y_val, lr_clf_probs[:,1]))\n",
        "print('Accuracy: ', lr_clf.score(cleaned_X_val_df, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nIXCtQ_5JaSv"
      },
      "outputs": [],
      "source": [
        "# Save linear reg model\n",
        "with open('lr_clf', 'wb') as c:\n",
        "    pickle.dump(lr_clf, c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWt9LnR-zSBl"
      },
      "source": [
        "#lightGBM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "yzfsTOZgpn6q"
      },
      "outputs": [],
      "source": [
        "# Setup grid search\n",
        "param_grid = {\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'num_leaves': [10, 20, 30],\n",
        "    'min_child_samples': [20, 30],\n",
        "    'subsample': [0.8, 0.9],\n",
        "    'colsample_bytree': [0.8, 0.9]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "# Define the LightGBM model\n",
        "lgb_model = lgb.LGBMClassifier(objective='binary', metric='auc')\n",
        "\n",
        "# Use GridSearchCV to search over the parameter grid\n",
        "lgb_grid_search = GridSearchCV(estimator=lgb_model, param_grid=param_grid, cv=3, scoring='roc_auc')\n",
        "lgb_grid_search.fit(cleaned_X_train_df, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print('Best parameters:', lgb_grid_search.best_params_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WAnAu4SwWZe",
        "outputId": "3b1e28e2-aaa5-4739-a1aa-da5cc3d3c6e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC:  0.799999897478365\n"
          ]
        }
      ],
      "source": [
        "# Prediction Probs\n",
        "lgb_clf_probs = lgb_grid_search.predict_proba(cleaned_X_val_df)\n",
        "print('AUC: ', roc_auc_score(y_val, lgb_clf_probs[:,1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "xsFYxsyTwR4C"
      },
      "outputs": [],
      "source": [
        "# Save the model with best params\n",
        "with open('lgb_clf', 'wb') as c:\n",
        "    pickle.dump(lgb_grid_search.best_estimator_, c)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsqC4Jw1OGMR"
      },
      "source": [
        "# Pred Probs on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "H5h_PB_kYI1D"
      },
      "outputs": [],
      "source": [
        "# Load LightGBM Model\n",
        "with open('/content/lgb_clf', 'rb') as c:\n",
        "    lgb_clf = pickle.load(c)\n",
        "\n",
        "# Load Logistic Reg Model\n",
        "with open('/content/lr_clf', 'rb') as c:\n",
        "    lr_clf = pickle.load(c)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "_tU9pIdwpn96"
      },
      "outputs": [],
      "source": [
        "lr_test_probs = lr_clf.predict_proba(cleaned_X_test_df)\n",
        "np.savetxt(\"/content/glmresults.csv\", lr_test_probs[:,1], delimiter=\",\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1CBM1m-HPQG8"
      },
      "outputs": [],
      "source": [
        "lgb_test_probs = lgb_clf.predict_proba(cleaned_X_test_df)\n",
        "np.savetxt(\"/content/nonglmresults.csv\", lgb_test_probs[:,1], delimiter=\",\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
